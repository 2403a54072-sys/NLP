{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/EDtck15qiSGS+hQbRugZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a54072-sys/NLP/blob/main/Lab_assignment_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJlxJGHX4or9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd6664e3"
      },
      "source": [
        "# Task\n",
        "Install NLTK and spaCy, then load a short paragraph of text. Count the total number of words, convert the text to lowercase, and finally, output the preprocessed lowercase text along with the word count."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066c589c"
      },
      "source": [
        "## Install and Import Libraries\n",
        "\n",
        "### Subtask:\n",
        "Install NLTK and spaCy, then import them into the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452c960f"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to install the `nltk` and `spacy` libraries using `pip`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dfc6a15",
        "outputId": "4f537069-7825-470b-89fd-9b87c32df662"
      },
      "source": [
        "pip install nltk spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3761d384"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the libraries are installed, I need to import them into the notebook as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93037d64",
        "outputId": "d1e33450-dfd2-49fe-8f1c-7c7eca5b6e46"
      },
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "print(\"NLTK and spaCy imported successfully.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK and spaCy imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51775ac6"
      },
      "source": [
        "## Load Text\n",
        "\n",
        "### Subtask:\n",
        "Load a short paragraph of text into a Python string variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba7be384"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define a Python string variable named `text` and assign a short paragraph of text to it as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "797070e0",
        "outputId": "80b52cba-162e-4604-f6c8-c3643b56bc17"
      },
      "source": [
        "text = \"Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, process, and generate human language. It combines computational linguistics, computer science, and AI to bridge the gap between human communication and machine comprehension. NLP has numerous applications, including language translation, sentiment analysis, spam detection, and chatbot development. Recent advancements in deep learning have significantly boosted NLP capabilities, leading to more accurate and sophisticated language models.\"\n",
        "print(\"Text loaded successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a1e83e6"
      },
      "source": [
        "## Preprocess Text: Count Words and Convert to Lowercase\n",
        "\n",
        "### Subtask:\n",
        "Count the total number of words in the loaded text and convert the entire text to lowercase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e542b5d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a254402"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d649554"
      },
      "source": [
        "**Reasoning**:\n",
        "To achieve the subtask, I will first convert the `text` to lowercase using the `lower()` string method. Then, to count the words, I will split the lowercase text into individual words. A simple way to do this is by splitting the string by whitespace, which will create a list of words. The length of this list will give the total word count."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63a805e"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the reasoning provided, I will convert the `text` to lowercase and then count the words by splitting the lowercase text into a list and getting its length.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cbfa2da",
        "outputId": "2bd265a0-e1d4-4e0c-bd99-52fc251f2448"
      },
      "source": [
        "lowercase_text = text.lower()\n",
        "words = lowercase_text.split()\n",
        "word_count = len(words)\n",
        "\n",
        "print(f\"Preprocessed Lowercase Text:\\n{lowercase_text}\")\n",
        "print(f\"\\nTotal Word Count: {word_count}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Lowercase Text:\n",
            "natural language processing (nlp) is a field of artificial intelligence that focuses on enabling computers to understand, process, and generate human language. it combines computational linguistics, computer science, and ai to bridge the gap between human communication and machine comprehension. nlp has numerous applications, including language translation, sentiment analysis, spam detection, and chatbot development. recent advancements in deep learning have significantly boosted nlp capabilities, leading to more accurate and sophisticated language models.\n",
            "\n",
            "Total Word Count: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8b728e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   The total number of words in the provided paragraph is 72.\n",
        "*   The preprocessed lowercase text is: \"natural language processing (nlp) is a field of artificial intelligence that focuses on enabling computers to understand, process, and generate human language. it combines computational linguistics, computer science, and ai to bridge the gap between human communication and machine comprehension. nlp has numerous applications, including language translation, sentiment analysis, spam detection, and chatbot development. recent advancements in deep learning have significantly boosted nlp capabilities, leading to more accurate and sophisticated language models.\"\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `nltk` and `spacy` libraries were successfully installed (already satisfied) and imported into the environment.\n",
        "*   A paragraph of text focusing on Natural Language Processing (NLP) was loaded into a string variable.\n",
        "*   The loaded text was successfully converted to its lowercase form.\n",
        "*   After converting to lowercase, the total number of words in the paragraph was accurately determined to be 72.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The preprocessing steps (lowercase conversion and word counting) lay the foundation for further text analysis, such as tokenization or stemming/lemmatization, which could be the next logical steps.\n",
        "*   The installed NLTK and spaCy libraries can now be leveraged for more advanced NLP tasks on this or other texts, such as part-of-speech tagging or named entity recognition.\n"
      ]
    }
  ]
}